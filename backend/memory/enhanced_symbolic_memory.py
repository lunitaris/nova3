"""
Extension du syst√®me de m√©moire symbolique avec int√©gration ChatGPT facultative.
"""
import os
import json
import logging
import time
import asyncio
from typing import Dict, List, Any, Optional, Tuple
from datetime import datetime
import aiohttp
import backoff

from backend.config import config
from backend.memory.symbolic_memory import symbolic_memory, SymbolicMemory
from backend.utils.profiler import profile

logger = logging.getLogger(__name__)
from backend.config import OPENAI_API_KEY

class EnhancedSymbolicMemory:
    """
    Extension du gestionnaire de m√©moire symbolique avec int√©gration ChatGPT optionnelle.
    """

    def __init__(self, base_memory: SymbolicMemory = None):
        self.base_memory = base_memory or symbolic_memory
        self.openai_api_key = OPENAI_API_KEY

        if self.openai_api_key:
            key_length = len(self.openai_api_key)
            first_chars = self.openai_api_key[:4] if key_length > 8 else ""
            last_chars = self.openai_api_key[-4:] if key_length > 8 else ""
            # logger.info(f"‚úÖ OpenAI API key configur√©e!")     ## DEBUG
        else:
            logger.warning("‚ö†Ô∏è Aucune cl√© API OpenAI configur√©e. L'extraction via ChatGPT ne sera pas disponible.")

    @property
    def is_chatgpt_enabled(self) -> bool:
        enabled = (
            hasattr(config.memory, "use_chatgpt_for_symbolic_memory") and 
            config.memory.use_chatgpt_for_symbolic_memory and
            self.openai_api_key
        )
        logger.debug(f"‚öôÔ∏è ChatGPT extraction enabled: {enabled} - Config: {getattr(config.memory, 'use_chatgpt_for_symbolic_memory', False)}, API key available: {bool(self.openai_api_key)}")
        return enabled

    @backoff.on_exception(backoff.expo, (aiohttp.ClientError, asyncio.TimeoutError), max_tries=3)
    async def _call_openai_api(self, prompt: str, model: str = "gpt-3.5-turbo") -> str:
        if not self.openai_api_key:
            raise ValueError("Cl√© API OpenAI non configur√©e")

        logger.info(f"üì§ Calling OpenAI API with model: {model}")
        logger.debug(f"üì§ Prompt: '{prompt[:100]}...'")
        async with aiohttp.ClientSession() as session:
            headers = {
                "Content-Type": "application/json",
                "Authorization": f"Bearer {self.openai_api_key}"
            }
            payload = {
                "model": model,
                "messages": [
                    {"role": "system", "content": "Tu es un assistant d'extraction d'informations symboliques intelligent, exhaustif, et structurant."},
                    {"role": "user", "content": prompt}
                ],
                "temperature": 0.2
            }
            async with session.post("https://api.openai.com/v1/chat/completions", headers=headers, json=payload, timeout=15) as response:
                if response.status != 200:
                    response_text = await response.text()
                    logger.error(f"Erreur API OpenAI: {response.status} - {response_text}")
                    raise Exception(f"Erreur API OpenAI: {response.status}")
                data = await response.json()
                return data["choices"][0]["message"]["content"]


    async def extract_entities_and_relations(self, text: str, confidence: float = 0.7) -> Dict[str, Any]:
        """
        Alias de compatibilit√© vers extract_entities_and_relations_with_chatgpt.
        Utilise l‚Äôextraction hybride (ChatGPT si activ√©, sinon fallback local).
        """
        return await self.extract_entities_and_relations_with_chatgpt(text, confidence)



    async def extract_entities_and_relations_with_chatgpt(self, text: str, confidence: float = 0.7) -> Dict[str, Any]:
        prompt_template = """
Analyse le texte ci-dessous et extrait toutes les entit√©s, attributs et relations possibles.
Inclut √©galement les pr√©f√©rences, r√¥les, professions, et toute information implicite √©vidente.

Texte :
"{text}"

Objectifs :
1. D√©tecte les entit√©s (nom, type comme person/place/device/concept/etc, attributs, confiance).
2. D√©duis toutes les relations logiques entre ces entit√©s (m√™me implicites ou affectives).
3. Garde un style synth√©tique, compact, mais pr√©cis. Ne rate rien.

Format attendu (JSON uniquement) :
```json
{
  "entities": [
    {
      "name": "Nom",
      "type": "person/place/device/concept/...",
      "attributes": {"key": "valeur", ...},
      "confidence": 0.9
    }
  ],
  "relations": [
    {
      "source": "Nom",
      "relation": "relation",
      "target": "Nom",
      "confidence": 0.9
    }
  ]
}
```"""
        prompt = prompt_template.replace("{text}", text)
        method_used = "local"
        result = {"entities": [], "relations": []}
        
        if self.is_chatgpt_enabled:
            try:
                logger.info("Tentative d'extraction via ChatGPT")
                response = await self._call_openai_api(prompt)

                # Nettoyer les balises Markdown si pr√©sentes
                if "```json" in response:
                    response = response.split("```json")[1].split("```")[0].strip()
                elif "```" in response:
                    response = response.split("```")[1].strip()

                try:
                    parsed = json.loads(response)
                    result["entities"] = parsed.get("entities", [])
                    result["relations"] = parsed.get("relations", [])
                except json.JSONDecodeError:
                    logger.error("(Enhanced memory) R√©ponse OpenAI invalide ou non JSON")
                    result["entities"] = []
                    result["relations"] = []

                if result["entities"]:
                    method_used = "chatgpt"
                    logger.info(f"(Ehanced memory) Extraction r√©ussie via ChatGPT: {len(result['entities'])} entit√©s, {len(result['relations'])} relations")
                else:
                    logger.warning("(Ehanced memory) Extraction via ChatGPT vide ou invalide, fallback vers extraction locale")

            except Exception as e:
                logger.error(f"(Ehanced memory) Erreur lors de l'extraction via ChatGPT, fallback vers extraction locale: {str(e)}")

        
        # Si ChatGPT n'est pas activ√© ou a √©chou√©, utiliser l'extracteur local
        # Si √©chec ou vide ‚Üí fallback local
        if method_used == "local" or not result.get("entities"):
            logger.info("(Ehanced memory) Utilisation de l'extracteur local")
            local_entities = await self.base_memory.extract_entities_from_text(text, confidence)
            local_relations = await self.base_memory.extract_relations_from_text(text, confidence)

            result["entities"] = local_entities
            result["relations"] = local_relations
            logger.info(f"(Ehanced memory) Extraction locale: {len(local_entities)} entit√©s, {len(local_relations)} relations")

        result["method_used"] = method_used
        logger.info(f"üß™ (Ehanced memory) M√©thode d'extraction utilis√©e : {method_used}")
        return result
    
    async def update_graph_from_text(self, text: str, confidence: float = 0.7, valid_from: str = None, valid_to: str = None) -> Dict[str, int]:
        """
        Met √† jour le graphe de connaissances √† partir d'un texte.
        Utilise l'extraction am√©lior√©e d'entit√©s et de relations.
        
        Args:
            text: Texte √† analyser
            confidence: Niveau de confiance par d√©faut
            valid_from: Date ISO de d√©but de validit√© (si None, date courante)
            valid_to: Date ISO de fin de validit√© (si None, pas de limite)
            
        Returns:
            Statistiques sur les mises √† jour (entit√©s et relations ajout√©es)
        """
        try:
            # Extraire les entit√©s et relations via la m√©thode am√©lior√©e
            extraction_result = await self.extract_entities_and_relations(text, confidence)
            
            # R√©cup√©rer la m√©thode utilis√©e pour les logs
            method_used = extraction_result.pop("method_used", "unknown")
            
            # Traiter les entit√©s extraites
            entities_added = 0
            entity_ids = {}
            
            for entity in extraction_result.get("entities", []):
                entity_confidence = entity.get("confidence", confidence)
                entity_attributes = entity.get("attributes", {})
                
                # Ajouter l'entit√© au graphe
                entity_id = self.base_memory.add_entity(
                    name=entity["name"],
                    entity_type=entity["type"],
                    attributes=entity_attributes,
                    confidence=entity_confidence,
                    valid_from=valid_from,
                    valid_to=valid_to
                )
                
                if entity_id:
                    entity_ids[entity["name"]] = entity_id
                    entities_added += 1
            
            # Traiter les relations extraites
            relations_added = 0
            logger.info(f"üì° (Ehanced memory) Relations re√ßues de l'extracteur : {extraction_result.get('relations', [])}")
            for relation in extraction_result.get("relations", []):
                source_name = relation.get("source")
                target_name = relation.get("target")
                relation_type = relation.get("relation")
                relation_confidence = relation.get("confidence", confidence)
                
                # V√©rifier que les entit√©s existent ou les cr√©er au besoin
                if source_name not in entity_ids:
                    source_id = self.base_memory.add_entity(
                        name=source_name,
                        entity_type="concept",  # Type par d√©faut
                        confidence=confidence * 0.8,  # Confiance r√©duite car entit√© implicite
                        valid_from=valid_from,
                        valid_to=valid_to
                    )
                    if source_id:
                        entity_ids[source_name] = source_id
                else:
                    source_id = entity_ids[source_name]
                
                if target_name not in entity_ids:
                    target_id = self.base_memory.add_entity(
                        name=target_name,
                        entity_type="concept",  # Type par d√©faut
                        confidence=confidence * 0.8,  # Confiance r√©duite car entit√© implicite
                        valid_from=valid_from,
                        valid_to=valid_to
                    )
                    if target_id:
                        entity_ids[target_name] = target_id
                else:
                    target_id = entity_ids[target_name]
                
                # Ajouter la relation si les deux entit√©s existent
                if source_id and target_id:
                    success = self.base_memory.add_relation(
                        source_id=source_id,
                        relation=relation_type,
                        target_id=target_id,
                        confidence=relation_confidence,
                        valid_from=valid_from,
                        valid_to=valid_to
                    )
                    
                    if success:
                        relations_added += 1
            
            return {
                "entities_added": entities_added,
                "relations_added": relations_added,
                "extraction_method": method_used
            }
            
        except Exception as e:
            logger.error(f"Erreur lors de la mise √† jour du graphe: {str(e)}")
            import traceback
            logger.error(traceback.format_exc())
            return {
                "entities_added": 0,
                "relations_added": 0,
                "error": str(e),
                "extraction_method": "failed"
            }

# Instance globale de la m√©moire symbolique am√©lior√©e
enhanced_symbolic_memory = EnhancedSymbolicMemory(symbolic_memory)