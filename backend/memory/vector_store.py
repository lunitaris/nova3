import os
import json
import time
import faiss
import numpy as np
import logging
from typing import List, Dict, Any, Optional, Tuple
from datetime import datetime
import pickle

# Remplacer HuggingFaceEmbeddings par FakeEmbeddings pour le d√©veloppement
from langchain_community.embeddings import FakeEmbeddings

from backend.config import config

# D√©sactiver explicitement les tentatives de chargement GPU
os.environ['FAISS_NO_GPU'] = '1'

logger = logging.getLogger(__name__)

class VectorMemoryStore:
    """
    Syst√®me de m√©moire vectorielle utilisant FAISS pour stocker et rechercher des souvenirs.
    """
    
    def __init__(self, embedding_dimension: int = None, index_path: str = None):
        """
        Initialise le stockage de m√©moire vectorielle.
        
        Args:
            embedding_dimension: Dimension des vecteurs d'embedding
            index_path: Chemin pour charger/sauvegarder l'index
        """
        self.embedding_dimension = embedding_dimension or config.memory.vector_dimension
        self.index_path = index_path or os.path.join(config.data_dir, "memories", "vector_index")
        self.metadata_path = os.path.join(config.data_dir, "memories", "vector_metadata.json")
        
        # Initialiser un mod√®le d'embedding factice pour le d√©veloppement
        self.embeddings = FakeEmbeddings(size=self.embedding_dimension)
        
        # Initialiser ou charger l'index
        self._initialize_index()
        
        # Charger les m√©tadonn√©es
        self.metadata = self._load_metadata()
        
        # ID actuel pour les nouveaux vecteurs
        self.current_id = max(map(int, self.metadata.keys()), default=0) + 1

        
    def _initialize_index(self):
        """Initialise ou charge l'index FAISS."""
        try:
            if os.path.exists(f"{self.index_path}.faiss"):
                logger.info("Chargement d'un index FAISS existant")
                self.index = faiss.read_index(f"{self.index_path}.faiss")
                logger.info(f"Index charg√© avec {self.index.ntotal} vecteurs")
            else:
                # Utiliser IndexIDMap avec un index IVF pour de meilleures performances CPU
                logger.info(f"Cr√©ation d'un nouvel index FAISS de dimension {self.embedding_dimension}")
                quantizer = faiss.IndexFlatL2(self.embedding_dimension)
                self.index = faiss.IndexIVFFlat(quantizer, self.embedding_dimension, config.memory.nlist)
                logger.info("Nouvel index cr√©√©")

            # Check si index d√©j√† entra√Æn√© sinon entra√Æner
            if not self.index.is_trained:
                fake_data = np.random.random((1000, self.embedding_dimension)).astype('float32')
                self.index.train(fake_data)

        except Exception as e:
            logger.error(f"Erreur lors de l'initialisation de l'index: {str(e)}")
            logger.info("Cr√©ation d'un nouvel index par d√©faut")
            self.index = faiss.IndexFlatL2(self.embedding_dimension)


    
    def _load_metadata(self) -> Dict[str, Dict[str, Any]]:
        """Charge les m√©tadonn√©es associ√©es aux vecteurs."""
        if os.path.exists(self.metadata_path):
            try:
                with open(self.metadata_path, 'r', encoding='utf-8') as f:
                    return json.load(f)
            except Exception as e:
                logger.error(f"Erreur lors du chargement des m√©tadonn√©es: {str(e)}")
                return {}
        return {}
    
    def _save_metadata(self):
        """Sauvegarde les m√©tadonn√©es associ√©es aux vecteurs."""
        try:
            os.makedirs(os.path.dirname(self.metadata_path), exist_ok=True)
            with open(self.metadata_path, 'w', encoding='utf-8') as f:
                json.dump(self.metadata, f, ensure_ascii=False, indent=2)
        except Exception as e:
            logger.error(f"Erreur lors de la sauvegarde des m√©tadonn√©es: {str(e)}")
            
    def _save_index(self):
        """Sauvegarde l'index FAISS."""
        try:
            os.makedirs(os.path.dirname(self.index_path), exist_ok=True)
            faiss.write_index(self.index, f"{self.index_path}.faiss")
            logger.info(f"Index sauvegard√© avec {self.index.ntotal} vecteurs")
        except Exception as e:
            logger.error(f"Erreur lors de la sauvegarde de l'index: {str(e)}")
    
    def add_memory(self, content: str, metadata: Dict[str, Any] = None, score_pertinence: float = None, source_conversation_id: str = None) -> int:
        """
        Ajoute un nouveau souvenir √† l'index.
        
        Args:
            content: Contenu textuel du souvenir
            metadata: M√©tadonn√©es associ√©es au souvenir
            score_pertinence: Score de pertinence (0-1), calcul√© automatiquement si non sp√©cifi√©
            source_conversation_id: ID de la conversation source
            
        Returns:
            ID du souvenir ajout√©
        """
        try:
            # G√©n√©rer l'embedding
            vector = self.embeddings.embed_query(content)
            vector_np = np.array([vector], dtype=np.float32)
            
            # Ajouter √† l'index
            self.index.add(vector_np)


            # üö® Limiter le nombre de vecteurs FAISS pour √©viter saturation m√©moire
            MAX_VECTORS = 10000
            if self.index.ntotal >= MAX_VECTORS:
                logger.warning("üí° Trop de vecteurs en m√©moire. Suppression des plus anciens.")
                oldest_ids = sorted(self.metadata.keys(), key=lambda k: self.metadata[k].get("timestamp", ""))[:100]
                for old_id in oldest_ids:
                    self.delete_memory(old_id)
                self.rebuild_index()

            # R√©cup√©rer l'index FAISS utilis√© (dernier ajout√©)
            faiss_idx = self.index.ntotal - 1
            
            # Calculer le score de pertinence si non sp√©cifi√©
            if score_pertinence is None:
                # Algorithme simple: longueur relative du contenu (jusqu'√† un maximum raisonnable)
                content_length = len(content.split())
                score_pertinence = min(content_length / 100, 1.0) * 0.7 + 0.3
                # Le score est entre 0.3 et 1.0, avec 0.3 comme score minimal
            
            # Pr√©parer les m√©tadonn√©es
            memory_id = str(self.current_id)
            memory_metadata = {
                "content": content,
                "timestamp": datetime.now().isoformat(),
                "score_pertinence": score_pertinence,
                "type": "explicit",
                "faiss_idx": faiss_idx,
                **(metadata or {})
            }
            
            # Ajouter le source_conversation_id si sp√©cifi√©
            if source_conversation_id:
                memory_metadata["source_conversation_id"] = source_conversation_id
                
            # Stocker les m√©tadonn√©es
            self.metadata[memory_id] = memory_metadata
            
            # Incr√©menter l'ID courant
            self.current_id += 1
            
            # Sauvegarder
            self._save_metadata()
            self._save_index()
            
            logger.info(f"Souvenir ajout√© avec l'ID {memory_id}, score: {score_pertinence:.2f}")
            return int(memory_id)
            
        except Exception as e:
            logger.error(f"Erreur lors de l'ajout d'un souvenir: {str(e)}")
            return -1
    
    def search_memories(self, query: str, k: int = 5, min_score: float = 0.0, max_age_days: int = None) -> List[Dict[str, Any]]:
        """
        Recherche des souvenirs pertinents.
        
        Args:
            query: Requ√™te textuelle
            k: Nombre de r√©sultats √† retourner
            min_score: Score minimal de pertinence pour filtrer les r√©sultats
            max_age_days: √Çge maximal des souvenirs en jours
            
        Returns:
            Liste des souvenirs pertinents avec leurs m√©tadonn√©es
        """
        try:
            # V√©rifier si l'index est vide
            if self.index.ntotal == 0:
                logger.info("Index vide, aucun souvenir disponible")
                return []
            
            # G√©n√©rer l'embedding de la requ√™te
            query_vector = self.embeddings.embed_query(query)
            query_vector_np = np.array([query_vector], dtype=np.float32)
            
            # Limiter k au nombre de vecteurs disponibles
            k = min(k, self.index.ntotal)
            
            # Rechercher les vecteurs les plus proches
            distances, indices = self.index.search(query_vector_np, k)
            
            # R√©cup√©rer les m√©tadonn√©es
            results = []
            for i, (dist, idx) in enumerate(zip(distances[0], indices[0])):
                # L'index retourn√© par FAISS correspond √† la position dans l'index
                # Nous devons retrouver l'ID correspondant dans les m√©tadonn√©es
                matching_ids = [mid for mid, mdata in self.metadata.items() 
                                if mdata.get("faiss_idx", None) == idx]
                
                if matching_ids:
                    memory_id = matching_ids[0]
                    metadata = self.metadata[memory_id].copy()
                    metadata["score"] = float(1.0 / (1.0 + dist))  # Convertir la distance en score
                    metadata["memory_id"] = memory_id
                    
                    # Filtrer par score de pertinence
                    if metadata.get("score_pertinence", 0) < min_score:
                        continue
                    
                    # Filtrer par √¢ge si sp√©cifi√©
                    if max_age_days is not None and "timestamp" in metadata:
                        try:
                            mem_date = datetime.fromisoformat(metadata["timestamp"])
                            age_days = (datetime.now() - mem_date).days
                            if age_days > max_age_days:
                                continue
                        except:
                            # Ignorer les erreurs de parsing de date
                            pass
                    
                    results.append(metadata)
            
            # Trier par score d√©croissant
            results.sort(key=lambda x: x["score"], reverse=True)
            
            return results
            
        except Exception as e:
            logger.error(f"Erreur lors de la recherche de souvenirs: {str(e)}")
            return []
    
    def delete_memory(self, memory_id: str) -> bool:
        """
        Supprime un souvenir.
        Note: La suppression dans FAISS est complexe, on marque simplement comme supprim√© dans les m√©tadonn√©es.
        
        Args:
            memory_id: ID du souvenir √† supprimer
            
        Returns:
            True si supprim√© avec succ√®s, False sinon
        """
        try:
            if memory_id in self.metadata:
                self.metadata[memory_id]["deleted"] = True
                self.metadata[memory_id]["deletion_timestamp"] = datetime.now().isoformat()
                self._save_metadata()
                logger.info(f"Souvenir {memory_id} marqu√© comme supprim√©")
                return True
            else:
                logger.warning(f"Souvenir {memory_id} non trouv√© pour suppression")
                return False
        except Exception as e:
            logger.error(f"Erreur lors de la suppression du souvenir {memory_id}: {str(e)}")
            return False

    def update_memory(self, memory_id: str, content: str = None, metadata: Dict[str, Any] = None, score_pertinence: float = None) -> bool:
        """
        Met √† jour un souvenir existant.
        Si le contenu est modifi√©, cela n√©cessite de r√©indexer.
        
        Args:
            memory_id: ID du souvenir √† mettre √† jour
            content: Nouveau contenu (facultatif)
            metadata: M√©tadonn√©es √† mettre √† jour (facultatif)
            score_pertinence: Nouveau score de pertinence (facultatif)
            
        Returns:
            True si mis √† jour avec succ√®s, False sinon
        """
        try:
            if memory_id not in self.metadata:
                logger.warning(f"Souvenir {memory_id} non trouv√© pour mise √† jour")
                return False
            
            if content:
                # Marquer l'ancien comme supprim√©
                self.delete_memory(memory_id)
                
                # Pr√©parer les m√©tadonn√©es combin√©es
                combined_metadata = self.metadata[memory_id].copy()
                if metadata:
                    combined_metadata.update(metadata)
                
                # Mettre √† jour le score de pertinence si sp√©cifi√©
                if score_pertinence is not None:
                    combined_metadata["score_pertinence"] = score_pertinence
                
                # Conserver l'ID de la conversation source si pr√©sent
                source_conversation_id = combined_metadata.get("source_conversation_id")
                
                # Ajouter le nouveau contenu avec les m√©tadonn√©es combin√©es
                new_id = self.add_memory(content, combined_metadata, 
                                         score_pertinence=combined_metadata.get("score_pertinence"),
                                         source_conversation_id=source_conversation_id)
                logger.info(f"Souvenir {memory_id} r√©index√© avec nouvel ID {new_id}")
                return True
            
            elif metadata or score_pertinence is not None:
                # Mise √† jour des m√©tadonn√©es uniquement
                if metadata:
                    self.metadata[memory_id].update(metadata)
                
                # Mettre √† jour le score de pertinence si sp√©cifi√©
                if score_pertinence is not None:
                    self.metadata[memory_id]["score_pertinence"] = score_pertinence
                
                self.metadata[memory_id]["updated_at"] = datetime.now().isoformat()
                self._save_metadata()
                logger.info(f"M√©tadonn√©es du souvenir {memory_id} mises √† jour")
                return True
                
            return False
            
        except Exception as e:
            logger.error(f"Erreur lors de la mise √† jour du souvenir {memory_id}: {str(e)}")
            return False

    def rebuild_index(self):
        """
        Reconstruit l'index FAISS √† partir des m√©tadonn√©es (utile pour le nettoyage).
        """
        try:
            # Cr√©er un nouvel index
            new_index = faiss.IndexFlatL2(self.embedding_dimension)
            
            # Mettre √† jour les m√©tadonn√©es
            updated_metadata = {}
            current_idx = 0
            
            for memory_id, metadata in self.metadata.items():
                # Ignorer les souvenirs supprim√©s
                if metadata.get("deleted", False):
                    continue
                
                # R√©cup√©rer le contenu
                content = metadata.get("content", "")
                if not content:
                    continue
                
                # G√©n√©rer l'embedding
                vector = self.embeddings.embed_query(content)
                vector_np = np.array([vector], dtype=np.float32)
                
                # Ajouter √† l'index
                new_index.add(vector_np)
                
                # Mettre √† jour les m√©tadonn√©es
                metadata["faiss_idx"] = current_idx
                updated_metadata[memory_id] = metadata
                current_idx += 1
            
            # Remplacer l'index et les m√©tadonn√©es
            self.index = new_index
            self.metadata = updated_metadata
            
            # Sauvegarder
            self._save_index()
            self._save_metadata()
            
            logger.info(f"Index reconstruit avec {self.index.ntotal} vecteurs")
            return True
            
        except Exception as e:
            logger.error(f"Erreur lors de la reconstruction de l'index: {str(e)}")
            return False
            
    def get_all_memories(self, include_deleted: bool = False) -> List[Dict[str, Any]]:
        """
        R√©cup√®re tous les souvenirs stock√©s avec leurs m√©tadonn√©es.
        
        Args:
            include_deleted: Si True, inclut √©galement les souvenirs supprim√©s
            
        Returns:
            Liste de tous les souvenirs avec leurs m√©tadonn√©es
        """
        memories = []
        
        for memory_id, metadata in self.metadata.items():
            # Ignorer les souvenirs supprim√©s si demand√©
            if not include_deleted and metadata.get("deleted", False):
                continue
                
            # Copier les m√©tadonn√©es et ajouter l'ID
            memory_data = metadata.copy()
            memory_data["memory_id"] = memory_id
            
            # Si l'ID FAISS n'est pas n√©cessaire, le supprimer pour clart√©
            if "faiss_idx" in memory_data:
                del memory_data["faiss_idx"]
                
            memories.append(memory_data)
            
        return memories

# Instance globale du gestionnaire de m√©moire vectorielle
vector_store = VectorMemoryStore()