from fastapi import APIRouter, WebSocket, WebSocketDisconnect, HTTPException, Depends, File, UploadFile, Form, Query
from fastapi.responses import JSONResponse
from pydantic import BaseModel
from typing import Optional, List, Dict, Any
import json
import logging
import asyncio
from datetime import datetime


import os
import networkx as nx
from backend.config import config
from backend.memory.symbolic_memory import symbolic_memory


# Importations absolues au lieu d'importations relatives
from backend.memory.conversation import conversation_manager
from backend.models.model_manager import model_manager
from backend.utils.profiler import profile

logger = logging.getLogger(__name__)

router = APIRouter(prefix="/api/chat", tags=["chat"])

# Mod√®les de donn√©es
class ChatMessage(BaseModel):
    content: str
    mode: str = "chat"  # "chat" ou "voice"
    conversation_id: Optional[str] = None
    user_id: Optional[str] = "anonymous"

class ChatResponse(BaseModel):
    response: str
    conversation_id: str
    timestamp: str
    mode: str
    error: Optional[str] = None

class ConversationInfo(BaseModel):
    conversation_id: str
    title: str
    last_updated: str
    message_count: int
    summary: Optional[str] = None
    topics: Optional[List[str]] = None

# Endpoints
@router.post("/send", response_model=ChatResponse)
async def send_message(message: ChatMessage):
    """
    Envoie un message et re√ßoit une r√©ponse.
    """
    logger.info("üì© API: requ√™te /send - mode=%s, conv_id=%s", message.mode, message.conversation_id)
    try:
        start_time = time.time()
        logger.info("üß† API: initialisation mise √† jour symbolique")
        # 1. Injecter le message dans la m√©moire symbolique
        asyncio.create_task(symbolic_memory.update_graph_from_text(message.content))


        process_start = time.time()
        logger.info("‚öôÔ∏è API: appel au ConversationManager.process_user_input")
        # 2. Puis traitement normal de la conversation
        response = await conversation_manager.process_user_input(
            conversation_id=message.conversation_id,
            user_input=message.content,
            user_id=message.user_id,
            mode=message.mode
        )
        process_time = time.time() - process_start
        logger.info("‚úÖ API: r√©ponse g√©n√©r√©e en %.2f secondes", process_time)
        total_time = time.time() - start_time
        logger.info("üèÅ API: traitement total /send en %.2f secondes", total_time)
        
        return ChatResponse(**response)
    
    except Exception as e:
        logger.error(f"Erreur lors du traitement du message: {str(e)}")
        raise HTTPException(status_code=500, detail=f"Erreur de traitement: {str(e)}")


@router.get("/conversations", response_model=List[ConversationInfo])
async def list_conversations(
    user_id: str = Query("anonymous", alias="user_id"),
    limit: int = Query(10, ge=1, le=100),
    offset: int = Query(0, ge=0),
    include_latest: bool = Query(True)  # Nouveau param√®tre pour inclure la derni√®re conversation
):
    """
    Liste les conversations disponibles.
    """
    try:
        # R√©cup√©rer les conversations normalement
        conversations = conversation_manager.list_conversations(
            user_id=user_id,
            limit=limit,
            offset=offset
        )
        
        # Log pour d√©bogage
        logger.info(f"R√©cup√©ration de {len(conversations)} conversations pour l'utilisateur {user_id}")
        
        return conversations
    
    except Exception as e:
        logger.error(f"Erreur lors de la liste des conversations: {str(e)}")
        raise HTTPException(status_code=500, detail=f"Erreur: {str(e)}")

@router.get("/conversation/{conversation_id}", response_model=Dict[str, Any])
async def get_conversation(
    conversation_id: str,
    limit: int = Query(50, ge=1, le=200),
    include_metadata: bool = False
):
    """
    R√©cup√®re les messages d'une conversation.
    """
    try:
        conversation = conversation_manager.get_conversation(conversation_id)
        messages = conversation.get_messages(limit=limit, include_metadata=include_metadata)
        
        return {
            "conversation_id": conversation_id,
            "messages": messages,
            "metadata": conversation.metadata
        }
    
    except Exception as e:
        logger.error(f"Erreur lors de la r√©cup√©ration de la conversation {conversation_id}: {str(e)}")
        raise HTTPException(status_code=404, detail=f"Conversation non trouv√©e: {str(e)}")

@router.delete("/conversation/{conversation_id}")
async def delete_conversation(conversation_id: str):
    """
    Supprime une conversation.
    """
    try:
        success = conversation_manager.delete_conversation(conversation_id)
        
        if success:
            return {"status": "success", "message": "Conversation supprim√©e"}
        else:
            raise HTTPException(status_code=404, detail="Conversation non trouv√©e")
    
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"Erreur lors de la suppression de la conversation {conversation_id}: {str(e)}")
        raise HTTPException(status_code=500, detail=f"Erreur: {str(e)}")

@router.post("/conversation/{conversation_id}/clear")
async def clear_conversation_history(conversation_id: str):
    """
    Efface l'historique d'une conversation tout en conservant ses m√©tadonn√©es.
    """
    try:
        conversation = conversation_manager.get_conversation(conversation_id)
        conversation.clear_history()
        
        return {"status": "success", "message": "Historique de conversation effac√©"}
    
    except Exception as e:
        logger.error(f"Erreur lors de l'effacement de l'historique {conversation_id}: {str(e)}")
        raise HTTPException(status_code=500, detail=f"Erreur: {str(e)}")

# Gestionnaire de WebSocket pour les discussions en streaming
class ConnectionManager:
    def __init__(self):
        self.active_connections: Dict[str, WebSocket] = {}

    async def connect(self, websocket: WebSocket, client_id: str):
        await websocket.accept()
        self.active_connections[client_id] = websocket
        logger.info(f"Client WebSocket {client_id} connect√©. Total: {len(self.active_connections)}")

    def disconnect(self, client_id: str):
        if client_id in self.active_connections:
            del self.active_connections[client_id]
            logger.info(f"Client WebSocket {client_id} d√©connect√©. Total: {len(self.active_connections)}")

    async def send_message(self, client_id: str, message: str):
        if client_id in self.active_connections:
            await self.active_connections[client_id].send_text(message)

manager = ConnectionManager()

@router.websocket("/ws/{client_id}")
async def websocket_endpoint(websocket: WebSocket, client_id: str):
    await manager.connect(websocket, client_id)
    try:
        while True:
            data = await websocket.receive_text()
            
            try:
                # Analyser le message JSON
                message_data = json.loads(data)
                logger.info("üîÑ WebSocket: message re√ßu - client=%s", client_id)
                logger.debug(f"üîÑ WebSocket: message re√ßu {message_data}")

                
                # Extraire les informations
                conversation_id = message_data.get("conversation_id")
                content = message_data.get("content", "")
                mode = message_data.get("mode", "chat")
                user_id = message_data.get("user_id", "anonymous")
                logger.info("üß† WebSocket: traitement de la requ√™te - conv_id=%s, len=%d", conversation_id, len(content))
                

                start_time = time.time()
                if not content:
                    await websocket.send_json({
                        "type": "error",
                        "content": "Message vide"
                    })
                    continue
                
                # Envoyer un message de d√©but explicite
                await websocket.send_json({
                    "type": "start",
                    "content": "",
                    "conversation_id": conversation_id
                })
                
                # Ajouter le message utilisateur
                conversation = conversation_manager.get_conversation(conversation_id, user_id)
                message = conversation.add_message(content, role="user", metadata={"mode": mode})
                
                # Cr√©er une version simplifi√©e de la g√©n√©ration avec streaming manuel
                try:
                    # Pr√©parer le prompt
                    prompt = f"""{content}

Tu es une intelligence artificielle locale con√ßue pour assister un humain nomm√© Ma√´l.

Ta mission :
- Fournir une r√©ponse directe √† chaque demande de Ma√´l.
- Ne r√©p√®te jamais ce que Ma√´l a dit.
- Ne reformule pas ses phrases inutilement.
- Sois claire, concise et efficace.
- Adopte un ton oral naturel, adapt√© √† une conversation vocale courte.
- Ne t'√©tale pas : vise la bri√®vet√© sauf si plus de contexte est n√©cessaire.
- Ne fais pas d‚Äôintroduction, ni de r√©sum√©.
- N‚Äôinvente rien si tu ne sais pas : dis-le simplement.
- Utilise un ton non formel, amical. Tutoie l'utilisateur qui te parle.

Ma√´l peut t‚Äôenvoyer des informations sur lui-m√™me. Tu dois les retenir mentalement si utile, mais ne pas les reformuler √† voix haute.
Langue : R√©ponds en fran√ßais si Ma√´l √©crit en fran√ßais.

Commence ta r√©ponse maintenant :"""
                    
                    # Utiliser le model manager pour obtenir le mod√®le adapt√©, mais sans streaming
                    model = model_manager._get_appropriate_model(prompt, "auto", None)
                    
                    # G√©n√©rer la r√©ponse compl√®te sans streaming
                    @profile("llm_ainvoke")
                    async def _call_llm(m, p):
                        return await m.ainvoke(p)
                    response_text = await _call_llm(model, prompt)
                    
                    # Simuler le streaming en envoyant des tokens manuellement
                    last_sent = 0
                    token_size = 5  # Envoyer 5 caract√®res √† la fois
                    
                    while last_sent < len(response_text):
                        # Extraire le prochain "token"
                        end = min(last_sent + token_size, len(response_text))
                        token = response_text[last_sent:end]
                        last_sent = end
                        
                        # Envoyer le token
                        await websocket.send_json({
                            "type": "token",
                            "content": token
                        })
                        
                        # Pause pour simuler le streaming naturel
                        await asyncio.sleep(0.1)
                    
                    # Ajouter la r√©ponse √† la conversation
                    conversation.add_message(response_text, role="assistant", metadata={"mode": mode})
                    
                    # Envoyer le message de fin
                    await websocket.send_json({
                        "type": "end",
                        "content": response_text,
                        "conversation_id": conversation.conversation_id,
                        "timestamp": datetime.now().isoformat()
                    })
                    
                except Exception as e:
                    logger.error(f"Erreur lors de la g√©n√©ration: {str(e)}")
                    import traceback
                    logger.error(traceback.format_exc())
                    
                    await websocket.send_json({
                        "type": "error",
                        "content": f"Erreur: {str(e)}"
                    })

                process_time = time.time() - start_time
                logger.info("‚è±Ô∏è WebSocket: requ√™te trait√©e en %.2f secondes", process_time)
                
            except json.JSONDecodeError:
                logger.error(f"Format JSON invalide: {data}")
                await websocket.send_json({
                    "type": "error",
                    "content": "Format JSON invalide"
                })
            except Exception as e:
                logger.error(f"Erreur WebSocket: {str(e)}")
                await websocket.send_json({
                    "type": "error",
                    "content": f"Erreur: {str(e)}"
                })
                
    except WebSocketDisconnect:
        manager.disconnect(client_id)




@router.get("/conversation/{conversation_id}/graph")
async def get_conversation_graph(
    conversation_id: str,
    include_deleted: bool = Query(False, description="Inclure les entit√©s supprim√©es")
):
    """
    R√©cup√®re le graphe symbolique pour une conversation sp√©cifique.
    Redirection vers l'endpoint unifi√© de l'API memory.
    """
    try:
        # V√©rifier si la conversation existe
        conversation_file_path = os.path.join(config.data_dir, "conversations", f"{conversation_id}.json")
        if not os.path.exists(conversation_file_path):
            raise HTTPException(status_code=404, detail=f"Conversation {conversation_id} non trouv√©e")
        
        # Rediriger vers l'API unifi√©e de graphe avec le param√®tre conversation_id
        from backend.api.memory import get_memory_graph
        
        # Appeler l'API unifi√©e
        return await get_memory_graph(
            format="d3",
            include_expired=include_deleted,  # Note: renamed from include_deleted for consistency
            conversation_id=conversation_id
        )
        
    except Exception as e:
        logger.error(f"Erreur lors de la r√©cup√©ration du graphe pour la conversation {conversation_id}: {str(e)}")
        raise HTTPException(status_code=500, detail=f"Erreur: {str(e)}")




def _get_node_group(entity_type: str) -> int:
    """
    Attribue un groupe (utilis√© pour la couleur) selon le type d'entit√©.
    """
    type_groups = {
        "person": 1,
        "place": 2,
        "date": 3,
        "concept": 4,
        "preference": 5,
        "profession": 6,
        "contact": 7,
        "device": 8,
        "user": 0  # Utilisateurs en groupe sp√©cial
    }
    
    return type_groups.get(entity_type.lower(), 9)  # 9 = autre type